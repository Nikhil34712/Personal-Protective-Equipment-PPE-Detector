{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAn2MlmMc1bA",
        "outputId": "9344de2f-18bd-46ee-c899-beee14909b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ppe_detection\n"
          ]
        }
      ],
      "source": [
        "# Create base project directory\n",
        "!mkdir -p /content/drive/MyDrive/ppe_detection\n",
        "%cd /content/drive/MyDrive/ppe_detection\n",
        "\n",
        "# Create directory structure\n",
        "!mkdir -p config src\n",
        "\n",
        "# Create empty files\n",
        "!touch src/__init__.py\n",
        "!touch src/config.py\n",
        "!touch src/dataset.py\n",
        "!touch src/train.py\n",
        "!touch src/utils.py\n",
        "!touch src/inference.py\n",
        "!touch requirements.txt\n",
        "!touch main.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/config/data.yaml\n",
        "train: /content/drive/MyDrive/ppe_detection/dataset/train\n",
        "val: /content/drive/MyDrive/ppe_detection/dataset/valid\n",
        "test: /content/drive/MyDrive/ppe_detection/dataset/test\n",
        "\n",
        "nc: 12\n",
        "names: ['glove', 'goggles', 'helmet', 'mask', 'no-suit', 'no_glove', 'no_goggles', 'no_helmet', 'no_mask', 'no_shoes', 'shoes', 'suit']\n",
        "\n",
        "roboflow:\n",
        "  workspace: personal-protective-equipment\n",
        "  project: ppes-kaxsi\n",
        "  version: 8\n",
        "  license: CC BY 4.0\n",
        "  url: https://universe.roboflow.com/personal-protective-equipment/ppes-kaxsi/dataset/8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCc36nNDc_dk",
        "outputId": "f0c22240-6a1d-4b45-d4af-7a563f8483a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/config/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"fGbCADJ8D90SfaKuRfxB\")\n",
        "project = rf.workspace(\"personal-protective-equipment\").project(\"ppes-kaxsi\")\n",
        "dataset = project.version(8).download(\"yolov5\", location=\"/content/drive/MyDrive/ppe_detection/dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPAuMdVMeBB6",
        "outputId": "af6c1543-e759-4d28-e7a9-3908a91ba67c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.48-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "Downloading roboflow-1.1.48-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.48\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/drive/MyDrive/ppe_detection/dataset to yolov5pytorch:: 100%|██████████| 883689/883689 [00:20<00:00, 43690.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/drive/MyDrive/ppe_detection/dataset in yolov5pytorch:: 100%|██████████| 49860/49860 [00:09<00:00, 5099.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "ultralytics\n",
        "torch\n",
        "torchvision\n",
        "opencv-python\n",
        "pandas\n",
        "numpy\n",
        "albumentations\n",
        "wandb\n",
        "PyYAML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikCKlJlHdHvm",
        "outputId": "7fcf6dab-b71f-4e67-8680-d13ae1ced5b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfgQ-_OUdLQQ",
        "outputId": "9ff48f0b-a06f-4ff1-a50f-b712b7f41f53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics (from -r requirements.txt (line 1))\n",
            "  Downloading ultralytics-8.3.20-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.4.15)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.18.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (6.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (10.4.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 1))\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2024.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 7)) (0.24.0)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 7)) (2.9.2)\n",
            "Requirement already satisfied: albucore>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 7)) (0.0.16)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 7)) (4.10.0.84)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 8)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->-r requirements.txt (line 7)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations->-r requirements.txt (line 7)) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations->-r requirements.txt (line 7)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (5.0.1)\n",
            "Downloading ultralytics-8.3.20-py3-none-any.whl (876 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m876.6/876.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.20 ultralytics-thop-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/src/config.py\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "import yaml\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    img_size: int = 416\n",
        "    batch_size: int = 16\n",
        "    epochs: int = 20\n",
        "    model_type: str = 'yolov8m.pt'\n",
        "    lr0: float = 0.01\n",
        "    weight_decay: float = 0.0005\n",
        "    patience: int = 20\n",
        "    classes: List[str] = ('glove', 'goggles', 'helmet', 'mask', 'no-suit',\n",
        "                         'no_glove', 'no_goggles', 'no_helmet', 'no_mask',\n",
        "                         'no_shoes', 'shoes', 'suit')\n",
        "\n",
        "# Notice this function is NOT indented under the class\n",
        "def load_config(yaml_path='/content/drive/MyDrive/ppe_detection/config/data.yaml'):\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    return ModelConfig(), data_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJiCNodOdQ-4",
        "outputId": "fc405595-eb04-4305-9562-d179d9a2c1a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/src/config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/src/dataset.py\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "from collections import Counter\n",
        "\n",
        "class PPEDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, transform=None):\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.label_dir = Path(label_dir)\n",
        "        self.transform = transform\n",
        "        self.image_files = list(self.img_dir.glob('*.jpg'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        label_path = self.label_dir / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        labels = []\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                labels = [line.strip().split() for line in f]\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, bboxes=labels)\n",
        "            image = transformed['image']\n",
        "            labels = transformed['bboxes']\n",
        "\n",
        "        return image, labels\n",
        "\n",
        "def analyze_dataset(data_path: str, classes):\n",
        "    data_path = Path(data_path)\n",
        "    labels_path = data_path / 'labels'\n",
        "    class_distribution = Counter()\n",
        "\n",
        "    for label_file in labels_path.glob('*.txt'):\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])\n",
        "                class_distribution[class_id] += 1\n",
        "\n",
        "    print(\"\\nClass Distribution\")\n",
        "    for class_id, count in class_distribution.items():\n",
        "        print(f\"Class {classes[class_id]}: {count}\")\n",
        "\n",
        "    return class_distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKZh1ZxzdYrH",
        "outputId": "cf7f80db-d402-4d1e-ba5d-6568686895e8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/src/dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/src/utils.py\n",
        "from pathlib import Path\n",
        "\n",
        "def verify_dataset(data_path: str):\n",
        "    data_path = Path(data_path)\n",
        "\n",
        "    # Check if the main directory exists\n",
        "    if not data_path.exists():\n",
        "        raise ValueError(f\"Dataset directory does not exist: {data_path}\")\n",
        "\n",
        "    # Check for images and labels directories\n",
        "    images_path = data_path / 'images'\n",
        "    labels_path = data_path / 'labels'\n",
        "\n",
        "    if not images_path.exists():\n",
        "        raise ValueError(f\"Missing directory: {images_path}\")\n",
        "    if not labels_path.exists():\n",
        "        raise ValueError(f\"Missing directory: {labels_path}\")\n",
        "\n",
        "    # Verify matching images and labels\n",
        "    image_files = set(f.stem for f in images_path.glob('*.jpg'))\n",
        "    label_files = set(f.stem for f in labels_path.glob('*.txt'))\n",
        "\n",
        "    if image_files != label_files:\n",
        "        print(f\"Warning: Mismatched images and labels in {data_path}\")\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iniqI4IGluh3",
        "outputId": "f6220872-460e-48b3-b3c4-1695f13aeba0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/src/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/src/train.py\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import wandb\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "def train_model(config, data_config):\n",
        "    wandb.init(project='PPE-Detection', config=vars(config))\n",
        "\n",
        "    # Create a temporary YAML file with the data configuration\n",
        "    yaml_path = Path('temp_data_config.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(data_config, f)\n",
        "\n",
        "    model = YOLO(config.model_type)\n",
        "\n",
        "    results = model.train(\n",
        "        data=str(yaml_path),  # Pass the path to the YAML file as string\n",
        "        epochs=config.epochs,\n",
        "        imgsz=config.img_size,\n",
        "        batch=config.batch_size,\n",
        "        patience=config.patience,\n",
        "        lr0=config.lr0,\n",
        "        weight_decay=config.weight_decay,\n",
        "        cache=True,\n",
        "        device='0' if torch.cuda.is_available() else 'cpu',\n",
        "        project='PPE-Detection',\n",
        "        name='PPE_Detector',\n",
        "        exist_ok=True,\n",
        "        pretrained=True,\n",
        "        optimizer='Adam',\n",
        "        resume = True\n",
        "    )\n",
        "\n",
        "    # Clean up temporary file\n",
        "    yaml_path.unlink(missing_ok=True)\n",
        "\n",
        "    return model, results\n",
        "\n",
        "def validate_model(model, valid_path):\n",
        "    results = model.val(data=valid_path)\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nWgv9m-FJhU",
        "outputId": "8d76099e-2c63-4729-eb8d-27a760e0b6c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/src/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/src/inference.py\n",
        "\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def inference_pipeline(model_path: str, image_path: str, conf_thresh: float = 0.25):\n",
        "  model = YOLO(model_path)\n",
        "\n",
        "  results = model.predict(\n",
        "      source = image_path,\n",
        "      conf = conf_thresh,\n",
        "      iou = 0.45,\n",
        "      show = True,\n",
        "      save = True\n",
        "  )\n",
        "  return results\n",
        "\n",
        "def process_results(results, image, classes):\n",
        "  processed_image = image.copy()\n",
        "\n",
        "  for result in results:\n",
        "    boxes = result.boxes\n",
        "    for box in boxes:\n",
        "      x1, y1, x2, y2 = box.xyxy[0]\n",
        "      conf = box.conf[0]\n",
        "      cls_id = int(box.cls[0])\n",
        "      cls_name = classes[cls_id]\n",
        "\n",
        "\n",
        "      cv2.rectangle(processed_image,\n",
        "                    (int(x1), int(y1)),\n",
        "                    (int(x2), int(y2)),\n",
        "                    (0, 255, 0), 2)\n",
        "\n",
        "      cv2.putText(processed_image,\n",
        "                  f\"{cls_name} {conf:.2f}\",\n",
        "                  (int(x1), int(y1 - 10)),\n",
        "                  cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                  0.9, (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "\n",
        "    return processed_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guS2SOPHdrR0",
        "outputId": "54c6869f-c3c9-48d3-9aab-2935f8c3fd88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/src/inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ppe_detection/main.py\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ppe_detection')\n",
        "\n",
        "from src.config import load_config\n",
        "from src.dataset import analyze_dataset\n",
        "from src.utils import verify_dataset\n",
        "from src.train import train_model, validate_model\n",
        "from src.inference import inference_pipeline, process_results\n",
        "import wandb\n",
        "import cv2\n",
        "\n",
        "def main():\n",
        "    # Load configurations\n",
        "    config, data_config = load_config()\n",
        "\n",
        "    # Verify and analyze dataset\n",
        "    verify_dataset(data_config['train'])\n",
        "    class_distribution = analyze_dataset(data_config['train'], config.classes)\n",
        "\n",
        "    # Initialize wandb\n",
        "    wandb.init(project=\"ppe-detection\")\n",
        "\n",
        "    try:\n",
        "        # Train model\n",
        "        model, training_results = train_model(config, data_config)\n",
        "\n",
        "        # Save model\n",
        "        model.save('/content/drive/MyDrive/ppe_detection/best_ppe_model.pt')\n",
        "\n",
        "        # Example inference\n",
        "        test_image_path = data_config['test'] + '/images/005303_jpg.rf.d88d9335996cf880d42a0754273536db.jpg'\n",
        "        original_image = cv2.imread(test_image_path)\n",
        "        if original_image is None:\n",
        "            raise ValueError(f\"Could not load image from {test_image_path}\")\n",
        "\n",
        "        test_results = inference_pipeline(\n",
        "            model_path='best_ppe_model.pt',\n",
        "            image_path=test_image_path\n",
        "        )\n",
        "\n",
        "        # Process and visualize results\n",
        "        processed_image = process_results(test_results[0], original_image, model.names)\n",
        "\n",
        "        # Save processed image\n",
        "        cv2.imwrite('/content/drive/MyDrive/ppe_detection/test_results.jpg', processed_image)\n",
        "\n",
        "        from google.colab.patches import cv2_imshow\n",
        "        cv2_imshow(processed_image)\n",
        "\n",
        "    finally:\n",
        "        wandb.finish()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooG2Muy8jlWC",
        "outputId": "5eb00da8-64cc-466d-e060-a6d48d489959"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ppe_detection/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ppe_detection/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rckumz1bfHJd",
        "outputId": "26c194d0-7406-4700-a73c-bdfc0b706a98"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution\n",
            "Class goggles: 8076\n",
            "Class no_glove: 13635\n",
            "Class glove: 10981\n",
            "Class no_goggles: 7891\n",
            "Class no_shoes: 60\n",
            "Class shoes: 42\n",
            "Class no-suit: 744\n",
            "Class suit: 363\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikhilgeddam75\u001b[0m (\u001b[33mnikhilgeddam75-nikhil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/ppe_detection/wandb/run-20241023_113031-fnzblsnr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-lake-6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nikhilgeddam75-nikhil/ppe-detection\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nikhilgeddam75-nikhil/ppe-detection/runs/fnzblsnr\u001b[0m\n",
            "Ultralytics 8.3.20 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=temp_data_config.yaml, epochs=500, time=None, patience=50, batch=16, imgsz=416, save=True, save_period=-1, cache=disk, device=0, workers=8, project=YOLOv8, name=yolov8m, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=yolov8m.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=True, dnn=False, plots=False, source=ultralytics/assets/, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.1, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=YOLOv8/yolov8m\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir YOLOv8/yolov8m', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3782644  ultralytics.nn.modules.head.Detect           [12, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25,863,268 parameters, 25,863,252 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/ppe_detection/dataset/train/labels.cache... 19419 images, 3 backgrounds, 0 corrupt: 100% 19419/19419 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (9.4GB Disk): 100% 19419/19419 [01:41<00:00, 190.67it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/ppe_detection/dataset/valid/labels.cache... 3570 images, 0 backgrounds, 0 corrupt: 100% 3570/3570 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.7GB Disk): 100% 3570/3570 [00:33<00:00, 107.12it/s]\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.001), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlunar-lake-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/nikhilgeddam75-nikhil/ppe-detection/runs/fnzblsnr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/nikhilgeddam75-nikhil/ppe-detection\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241023_113031-fnzblsnr/logs\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ppe_detection/main.py\", line 54, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/ppe_detection/main.py\", line 25, in main\n",
            "    model, training_results = train_model(config, data_config)\n",
            "  File \"/content/drive/MyDrive/ppe_detection/src/train.py\", line 17, in train_model\n",
            "    results = model.train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 802, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 207, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 327, in _do_train\n",
            "    self._setup_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 319, in _setup_train\n",
            "    self.resume_training(ckpt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 730, in resume_training\n",
            "    assert start_epoch > 0, (\n",
            "AssertionError: yolov8m.pt training to 500 epochs is finished, nothing to resume.\n",
            "Start a new training without resuming, i.e. 'yolo train model=yolov8m.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('/content/drive/MyDrive/ppe_detection/PPE-Detection/PPE_Detector/weights/best.pt')"
      ],
      "metadata": {
        "id": "LxwYYp1CjUa5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(source='/content/drive/MyDrive/ppe_detection/dataset/test/images/005384_jpg.rf.555416d9ce829859bf928b3b599d7d0c.jpg', conf=0.25, save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGtGlxcVMECO",
        "outputId": "d17e3298-c128-43f3-be53-00fb98a19e6d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/ppe_detection/dataset/test/images/005384_jpg.rf.555416d9ce829859bf928b3b599d7d0c.jpg: 416x416 (no detections), 22.5ms\n",
            "Speed: 1.3ms preprocess, 22.5ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.val(data='/content/drive/MyDrive/ppe_detection/config/data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVwgo1M9MU7b",
        "outputId": "40db1ef9-f946-4454-a722-400351fff3e0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.20 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/ppe_detection/dataset/valid/labels.cache... 3570 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3570/3570 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 224/224 [00:43<00:00,  5.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       3570       7710      0.264      0.359      0.247      0.132\n",
            "                 glove        448        984      0.799      0.873      0.881      0.461\n",
            "               goggles       1121       1192       0.84      0.563      0.656      0.395\n",
            "                helmet        237        283          0          0          0          0\n",
            "                  mask        253        253          0          0          0          0\n",
            "               no-suit         13         15     0.0138      0.733     0.0579     0.0506\n",
            "              no_glove        789       1548       0.67      0.652      0.626       0.29\n",
            "            no_goggles       1161       1384      0.794      0.482      0.631      0.314\n",
            "             no_helmet        205        229          0          0          0          0\n",
            "               no_mask        640        640          0          0          0          0\n",
            "              no_shoes        291        525    0.00618    0.00571    0.00576    0.00165\n",
            "                 shoes        348        639          0          0     0.0336    0.00587\n",
            "                  suit         18         18      0.039          1     0.0769     0.0699\n",
            "Speed: 0.2ms preprocess, 8.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiBsHLpRNd0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}